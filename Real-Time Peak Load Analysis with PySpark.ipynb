{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b3498b-ec9d-4485-9400-063692ce6fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "from pyspark.sql.functions import greatest\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FileStreamToMemory\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"one_hour\", DoubleType(), True),\n",
    "    StructField(\"two_hour\", DoubleType(), True),\n",
    "    StructField(\"three_hour\", DoubleType(), True),\n",
    "    StructField(\"four_hour\", DoubleType(), True),\n",
    "    StructField(\"five_hour\", DoubleType(), True),\n",
    "    StructField(\"six_hour\", DoubleType(), True),\n",
    "    StructField(\"seven_hour\", DoubleType(), True),\n",
    "    StructField(\"eight_hour\", DoubleType(), True),\n",
    "    StructField(\"nine_hour\", DoubleType(), True),\n",
    "    StructField(\"ten_hour\", DoubleType(), True),\n",
    "    StructField(\"eleven_hour\", DoubleType(), True),\n",
    "    StructField(\"twelve_hour\", DoubleType(), True),\n",
    "    StructField(\"thirteen_hour\", DoubleType(), True),\n",
    "    StructField(\"fourteen_hour\", DoubleType(), True),\n",
    "    StructField(\"fifteen_hour\", DoubleType(), True),\n",
    "    StructField(\"sixteen_hour\", DoubleType(), True),\n",
    "    StructField(\"seventeen_hour\", DoubleType(), True),\n",
    "    StructField(\"eighteen_hour\", DoubleType(), True),\n",
    "    StructField(\"nineteen_hour\", DoubleType(), True),\n",
    "    StructField(\"twenty_hour\", DoubleType(), True),\n",
    "    StructField(\"twenty_one_hour\", DoubleType(), True),\n",
    "    StructField(\"twenty_two_hour\", DoubleType(), True),\n",
    "    StructField(\"twenty_three_hour\", DoubleType(), True),\n",
    "    StructField(\"twenty_four_hour\", DoubleType(), True),\n",
    "    StructField(\"AVG_Temp\", DoubleType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d97ae8d-8f59-4e64-b4fb-b1521daef99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_stream_df = spark.readStream \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv(\"spark-warehouse\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78bd588-dfa0-41ca-a037-70d4b609cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_load_df = file_stream_df \\\n",
    "    .withColumn(\"PeakLoad\", \n",
    "        greatest(\n",
    "            \"one_hour\", \"two_hour\", \"three_hour\", \"four_hour\", \"five_hour\",\n",
    "            \"six_hour\", \"seven_hour\", \"eight_hour\", \"nine_hour\", \"ten_hour\",\n",
    "            \"eleven_hour\", \"twelve_hour\", \"thirteen_hour\", \"fourteen_hour\",\n",
    "            \"fifteen_hour\", \"sixteen_hour\", \"seventeen_hour\", \"eighteen_hour\",\n",
    "            \"nineteen_hour\", \"twenty_hour\", \"twenty_one_hour\", \"twenty_two_hour\",\n",
    "            \"twenty_three_hour\", \"twenty_four_hour\"\n",
    "        )\n",
    "    ) \\\n",
    "    .groupBy(\"Date\") \\\n",
    "    .agg({\"PeakLoad\": \"max\"}) \\\n",
    "    .withColumnRenamed(\"max(PeakLoad)\", \"PeakLoad\") \\\n",
    "    .orderBy(\"Date\")  \n",
    "\n",
    "query = peak_load_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"peak_load_data\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f2d0f-aaba-4c35-8c4c-d5968a843ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|Date      |PeakLoad|\n",
      "+----------+--------+\n",
      "|01/01/2010|17190.0 |\n",
      "|01/01/2011|19500.0 |\n",
      "|01/01/2012|20660.0 |\n",
      "|01/01/2013|21625.0 |\n",
      "|01/01/2014|22325.0 |\n",
      "|01/02/2010|18080.0 |\n",
      "|01/02/2011|16250.0 |\n",
      "|01/02/2012|20430.0 |\n",
      "|01/02/2013|19800.0 |\n",
      "|01/02/2014|22050.0 |\n",
      "|01/03/2010|18025.0 |\n",
      "|01/03/2011|19200.0 |\n",
      "|01/03/2012|20775.0 |\n",
      "|01/03/2013|20000.0 |\n",
      "|01/03/2014|22403.0 |\n",
      "|01/04/2010|18660.0 |\n",
      "|01/04/2011|18350.0 |\n",
      "|01/04/2012|20700.0 |\n",
      "|01/04/2013|22750.0 |\n",
      "|01/04/2014|22495.0 |\n",
      "+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    peak_load_df = spark.table(\"peak_load_data\")\n",
    "    display(peak_load_df.show(truncate=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f20d5-cb9e-4b88-ac88-49994ce3c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d22ef-55d0-4495-9c9a-5a44afd51acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
